#                                    __   __  __
#                                    \ \ / / / /
#                                     \ V / / /
#                                      \_/  \/
#
#                                    V E C T O R
#                            Configuration Specification
#
# ------------------------------------------------------------------------------
# Website: https://vector.dev
# Docs: https://vector.dev/docs/
# Community: https://vector.dev/community
# ------------------------------------------------------------------------------
# The file contains a full specification for the `vector.toml` configuration
# file. It follows the TOML format and includes all options, types, and
# possible values.
#
# More info on Vector's configuration can be found at:
# /docs/setup/configuration/

# ------------------------------------------------------------------------------
# Global
# ------------------------------------------------------------------------------
# Global options are relevant to Vector as a whole and apply to global behavior.

#
# General
#

# The directory used for persisting Vector state, such as on-disk buffers, file
# checkpoints, and more. Please make sure the Vector project has write
# permissions to this dir.
#
# * optional
# * no default
# * type: string
data_dir = "/var/lib/vector"

# The list of DNS servers Vector will use to resolve DNS requests. When set
# Vector will ignore the system configuration and use only the list of DNS
# servers provided. If this option is not set then Vector will attempt to use
# the system configuration.
#
# * optional
# * no default
# * type: [string]
dns_servers = ["0.0.0.0:53"]

#
# Log schema
#

[.log_schema]
  # The key used to hold the log host. See the log data model page for more info.
  #
  # * optional
  # * default: "host"
  # * type: string
  host_key = "host"
  host_key = "@host"
  host_key = "instance"
  host_key = "machine"

  # The key used to hold the log message. See the log data model page for more
  # info.
  #
  # * optional
  # * default: "message"
  # * type: string
  message_key = "message"
  message_key = "@message"
  message_key = "msg"

  # The key used to represent when the log was generated. See the log data model
  # page for more info.
  #
  # * optional
  # * default: "timestamp"
  # * type: string
  timestamp_key = "timestamp"
  timestamp_key = "@timestamp"
  timestamp_key = "datetime"

# ------------------------------------------------------------------------------
# Sources
# ------------------------------------------------------------------------------
# Sources specify data sources and are responsible for ingesting data into
# Vector.

# Ingests data through the Docker engine daemon and outputs `log` events.
[sources.docker]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "docker"
  type = "docker"

  # Setting this to `false` will disable the automatic merging of partial events.
  #
  # * optional
  # * default: true
  # * type: bool
  auto_partial_merge = true
  auto_partial_merge = false

  # A list of container IDs _or_ names to match against. Prefix matches are
  # supported, meaning you can supply just the first few characters of the
  # container ID or name. If not provided, all containers will be included.
  #
  # * optional
  # * no default
  # * type: [string]
  include_containers = ["serene_", "serene_leakey", "ad08cc418cf9"]

  # A list of image names to match against. If not provided, all images will be
  # included.
  #
  # * optional
  # * no default
  # * type: [string]
  include_images = ["httpd", "redis"]

  # A list of container object labels to match against when filtering running
  # containers. This should follow the described label's synatx in docker object
  # labels docs.
  #
  # * optional
  # * no default
  # * type: [string]
  include_labels = ["com.example.vendor=Timber Inc.", "com.example.name=Vector"]

  # The field name to be added to events that are detected to contain an
  # incomplete message (i.e. partial events). If set to `""`, no field will be
  # added to partial event. This allows to opt-out of partial event detection.
  #
  # * optional
  # * default: "_partial"
  # * type: string
  partial_event_marker_field = "_partial"

# Ingests data through one or more local files and outputs `log` events.
[sources.file]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "file"
  type = "file"

  # Delay between file discovery calls. This controls the interval at which
  # Vector searches for files.
  #
  # * required
  # * default: 1000
  # * type: int
  # * unit: milliseconds
  glob_minimum_cooldown = 1000

  # Array of file patterns to include. Globbing is supported.
  #
  # * required
  # * type: [string]
  include = ["/var/log/nginx/*.log"]

  # For files with a stored checkpoint at startup, setting this option to `true`
  # will tell Vector to read from the beginning of the file instead of the stored
  # checkpoint.
  #
  # * required
  # * default: false
  # * type: bool
  start_at_beginning = false
  start_at_beginning = true

  # The directory used to persist file checkpoint positions. By default, the
  # global `data_dir` option is used. Please make sure the Vector project has
  # write permissions to this dir.
  #
  # * optional
  # * no default
  # * type: string
  data_dir = "/var/lib/vector"

  # Array of file patterns to exclude. Globbing is supported.*Takes precedence
  # over the `include` option.*
  #
  # * optional
  # * no default
  # * type: [string]
  exclude = ["/var/log/nginx/*.[0-9]*.log"]

  # Ignore files with a data modification date that does not exceed this age.
  #
  # * optional
  # * no default
  # * type: int
  # * unit: seconds
  ignore_older = 86400

  # The maximum number of a bytes a line can contain before being discarded. This
  # protects against malformed lines or tailing incorrect files.
  #
  # * optional
  # * default: 102400
  # * type: int
  # * unit: bytes
  max_line_bytes = 102400

  #
  # Context
  #

  # The key name added to each event with the full path of the file.
  #
  # * required
  # * default: "file"
  # * type: string
  file_key = "file"

  # The key name added to each event representing the current host. This can also
  # be globally set via the global `host_key` option.
  #
  # * required
  # * default: "host"
  # * type: string
  host_key = "host"

  #
  # Priority
  #

  # An approximate limit on the amount of data read from a single file at a given
  # time.
  #
  # * optional
  # * default: 2048
  # * type: int
  # * unit: bytes
  max_read_bytes = 2048

  # Instead of balancing read capacity fairly across all watched files,
  # prioritize draining the oldest files before moving on to read data from
  # younger files.
  #
  # * optional
  # * default: false
  # * type: bool
  oldest_first = false
  oldest_first = true

  #
  # Fingerprinting
  #

  [sources.file.fingerprinting]
    # The number of bytes read off the head of the file to generate a unique
    # fingerprint.
    #
    # * required
    # * default: 256
    # * type: int
    # * unit: bytes
    # * relevant when strategy = "checksum"
    fingerprint_bytes = 256

    # The number of bytes to skip ahead (or ignore) when generating a unique
    # fingerprint. This is helpful if all files share a common header.
    #
    # * required
    # * default: 0
    # * type: int
    # * unit: bytes
    # * relevant when strategy = "checksum"
    ignored_header_bytes = 0

    # The strategy used to uniquely identify files. This is important for
    # checkpointing when file rotation is used.
    #
    # * optional
    # * default: "checksum"
    # * type: string
    # * enum: "checksum" or "device_and_inode"
    strategy = "checksum"
    strategy = "device_and_inode"

  #
  # Multiline
  #

  [sources.file.multiline]
    # Condition regex pattern to look for. Exact behavior is configured via `mode`.
    #
    # * required
    # * type: string
    condition_pattern = "^[\\s]+"
    condition_pattern = "\\\\$"
    condition_pattern = "^(INFO|ERROR) "
    condition_pattern = ";$"

    # Mode of operation, specifies how the `condition_pattern` is interpreted.
    #
    # * required
    # * type: string
    # * enum: "continue_through", "continue_past", "halt_before", and "halt_with"
    mode = "continue_through"
    mode = "continue_past"
    mode = "halt_before"
    mode = "halt_with"

    # Start regex pattern to look for as a beginning of the message.
    #
    # * required
    # * type: string
    start_pattern = "^[^\\s]"
    start_pattern = "\\\\$"
    start_pattern = "^(INFO|ERROR) "
    start_pattern = "[^;]$"

    # The maximum time to wait for the continuation. Once this timeout is reached,
    # the buffered message is guaraneed to be flushed, even if incomplete.
    #
    # * required
    # * type: int
    # * unit: milliseconds
    timeout_ms = 1000
    timeout_ms = 600000

# Ingests data through log records from journald and outputs `log` events.
[sources.journald]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "journald"
  type = "journald"

  # The systemd journal is read in batches, and a checkpoint is set at the end of
  # each batch. This option limits the size of the batch.
  #
  # * optional
  # * default: 16
  # * type: int
  batch_size = 16

  # Include only entries from the current boot.
  #
  # * optional
  # * default: true
  # * type: bool
  current_boot_only = true
  current_boot_only = false

  # The directory used to persist the journal checkpoint position. By default,
  # the global `data_dir` is used. Please make sure the Vector project has write
  # permissions to this dir.
  #
  # * optional
  # * no default
  # * type: string
  data_dir = "/var/lib/vector"

  # The full path of the `journalctl` executable. If not set, Vector will search
  # the path for `journalctl`.
  #
  # * optional
  # * default: "journalctl"
  # * type: string
  journalctl_path = "/usr/local/bin/journalctl"

  # The list of units names to monitor. If empty or not present, all units are
  # accepted. Unit names lacking a `"."` will have `".service"` appended to make
  # them a valid service unit name.
  #
  # * optional
  # * default: []
  # * type: [string]
  units = ["ntpd", "sysinit.target"]

# Ingests data through Kafka 0.9 or later and outputs `log` events.
[sources.kafka]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "kafka"
  type = "kafka"

  # A comma-separated list of host and port pairs that are the addresses of the
  # Kafka brokers in a "bootstrap" Kafka cluster that a Kafka client connects to
  # initially to bootstrap itself.
  #
  # * required
  # * type: string
  bootstrap_servers = "10.14.22.123:9092,10.14.23.332:9092"

  # The consumer group name to be used to consume events from Kafka.
  #
  # * required
  # * type: string
  group_id = "consumer-group-name"

  # The Kafka topics names to read events from. Regex is supported if the topic
  # begins with `^`.
  #
  # * required
  # * type: [string]
  topics = ["^(prefix1|prefix2)-.+", "topic-1", "topic-2"]

  # If offsets for consumer group do not exist, set them using this strategy.
  # librdkafka documentation for `auto.offset.reset` option for explanation.
  #
  # * optional
  # * default: "largest"
  # * type: string
  auto_offset_reset = "smallest"
  auto_offset_reset = "earliest"
  auto_offset_reset = "beginning"
  auto_offset_reset = "largest"
  auto_offset_reset = "latest"
  auto_offset_reset = "end"
  auto_offset_reset = "error"

  # Maximum time the broker may wait to fill the response.
  #
  # * optional
  # * default: 100
  # * type: int
  # * unit: milliseconds
  fetch_wait_max_ms = 50
  fetch_wait_max_ms = 100

  # The log field name to use for the topic key. If unspecified, the key would
  # not be added to the log event. If the message has null key, then this field
  # would not be added to the log event.
  #
  # * optional
  # * no default
  # * type: string
  key_field = "user_id"

  # The Kafka session timeout in milliseconds.
  #
  # * optional
  # * default: 10000
  # * type: int
  # * unit: milliseconds
  session_timeout_ms = 5000
  session_timeout_ms = 10000

  # Default timeout for network requests.
  #
  # * optional
  # * default: 60000
  # * type: int
  # * unit: milliseconds
  socket_timeout_ms = 30000
  socket_timeout_ms = 60000

  #
  # Advanced
  #

  [sources.kafka.librdkafka_options]
    # The options and their values. Accepts `string` values.
    #
    # * optional
    # * no default
    # * type: string
    "client.id" = "${ENV_VAR}"
    "fetch.error.backoff.ms" = "1000"

  #
  # Tls
  #

  [sources.kafka.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509).
    #
    # * optional
    # * no default
    # * type: string
    ca_path = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12. If this is set and is not a PKCS#12
    # archive, `key_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_path = "/path/to/host_certificate.crt"

    # Enable TLS during connections to the remote.
    #
    # * optional
    # * default: false
    # * type: bool
    enabled = false
    enabled = true

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_path` is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

    # Absolute path to a certificate key file used to identify this connection, in
    # DER or PEM format (PKCS#8). If this is set, `crt_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_path = "/path/to/host_certificate.key"

# Ingests data through the Heroku Logplex HTTP Drain protocol and outputs `log` events.
[sources.logplex]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "logplex"
  type = "logplex"

  # The address to accept connections on. The address _must_ include a port.
  #
  # * required
  # * type: string
  address = "0.0.0.0:8088"

# Ingests data through the Prometheus text exposition format and outputs `metric` events.
[sources.prometheus]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "prometheus"
  type = "prometheus"

  # Host addresses to scrape metrics from.
  #
  # * required
  # * type: [string]
  hosts = ["http://localhost:9090"]

  # The interval between scrapes in seconds.
  #
  # * required
  # * type: int
  scrape_interval_secs = 1

# Ingests data through a socket, such as a TCP, UDP, or Unix socket and outputs `log` events.
[sources.socket]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "socket"
  type = "socket"

  # The address to listen for connections on, or `systemd#N` to use the Nth
  # socket passed by systemd socket activation. If an address is used it _must_
  # include a port.
  #
  # * required
  # * type: string
  # * relevant when mode = "tcp" or mode = "udp"
  address = "0.0.0.0:9000"
  address = "systemd"
  address = "systemd#3"

  # The type of socket to use.
  #
  # * required
  # * type: string
  # * enum: "tcp", "udp", and "unix"
  mode = "tcp"
  mode = "udp"
  mode = "unix"

  # The unix socket path. *This should be absolute path*.
  #
  # * required
  # * type: string
  # * relevant when mode = "unix"
  path = "/path/to/socket"

  # The timeout before a connection is forcefully closed during shutdown.
  #
  # * required
  # * default: 30
  # * type: int
  # * unit: seconds
  # * relevant when mode = "tcp"
  shutdown_timeout_secs = 30

  # The maximum bytes size of incoming messages before they are discarded.
  #
  # * optional
  # * default: 102400
  # * type: int
  # * unit: bytes
  max_length = 102400

  #
  # Context
  #

  # The key name added to each event representing the current host. This can also
  # be globally set via the global `host_key` option.
  #
  # * required
  # * default: "host"
  # * type: string
  host_key = "host"

# Ingests data through the Splunk HTTP Event Collector protocol and outputs `log` events.
[sources.splunk_hec]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "splunk_hec"
  type = "splunk_hec"

  # The address to accept connections on.
  #
  # * required
  # * default: "0.0.0.0:8088"
  # * type: string
  address = "0.0.0.0:8088"

  # If supplied, incoming requests must supply this token in the `Authorization`
  # header, just as a client would if it was communicating with the Splunk HEC
  # endpoint directly. If _not_ supplied, the `Authorization` header will be
  # ignored and requests will not be authenticated.
  #
  # * optional
  # * no default
  # * type: string
  token = "A94A8FE5CCB19BA61C4C08"

# Ingests data through the StatsD UDP protocol and outputs `metric` events.
[sources.statsd]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "statsd"
  type = "statsd"

  # UDP socket address to bind to.
  #
  # * required
  # * type: string
  address = "127.0.0.1:8126"

# Ingests data through standard input (STDIN) and outputs `log` events.
[sources.stdin]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "stdin"
  type = "stdin"

  # The maxiumum bytes size of a message before it is discarded.
  #
  # * optional
  # * default: 102400
  # * type: int
  # * unit: bytes
  max_length = 102400

  #
  # Context
  #

  # The key name added to each event representing the current host. This can also
  # be globally set via the global `host_key` option.
  #
  # * required
  # * default: "host"
  # * type: string
  host_key = "host"

# Ingests data through the Syslog protocol and outputs `log` events.
[sources.syslog]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "syslog"
  type = "syslog"

  # The input mode.
  #
  # * required
  # * type: string
  # * enum: "tcp", "udp", and "unix"
  mode = "tcp"
  mode = "udp"
  mode = "unix"

  # The TCP or UDP address to listen for connections on, or "systemd#N" to use
  # the Nth socket passed by systemd socket activation.
  #
  # * optional
  # * no default
  # * type: string
  # * relevant when mode = "tcp" or mode = "udp"
  address = "0.0.0.0:9000"
  address = "systemd"
  address = "systemd#2"

  # The maximum bytes size of incoming messages before they are discarded.
  #
  # * optional
  # * default: 102400
  # * type: int
  # * unit: bytes
  max_length = 102400

  # The unix socket path. *This should be absolute path.*
  #
  # * optional
  # * no default
  # * type: string
  # * relevant when mode = "unix"
  path = "/path/to/socket"

  #
  # Context
  #

  # The key name added to each event representing the current host. This can also
  # be globally set via the global `host_key` option.
  #
  # * required
  # * default: "host"
  # * type: string
  host_key = "host"

# Ingests data through another upstream `vector` sink and outputs `log` and `metric` events.
[sources.vector]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "vector"
  type = "vector"

  # The TCP address to listen for connections on, or `systemd#N to use the Nth
  # socket passed by systemd socket activation. If an address is used it _must_
  # include a port.
  #
  # * required
  # * type: string
  address = "0.0.0.0:9000"
  address = "systemd"
  address = "systemd#1"

  # The timeout before a connection is forcefully closed during shutdown.
  #
  # * required
  # * default: 30
  # * type: int
  # * unit: seconds
  shutdown_timeout_secs = 30


# ------------------------------------------------------------------------------
# Transforms
# ------------------------------------------------------------------------------
# Transforms parse, structure, and enrich events.

# Accepts and outputs `log` events allowing you to add one or more log fields.
[transforms.add_fields]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "add_fields"
  type = "add_fields"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  #
  # Fields
  #

  [transforms.add_fields.fields]
    # The name of the field to add. Accepts all supported types. Use `.` for adding
    # nested fields.
    #
    # * required
    # * type: *
    string_field = "string value"
    env_var_field = "${ENV_VAR}"
    int_field = 1
    float_field = 1.2
    bool_field = true
    timestamp_field = 1979-05-27T00:32:00Z
    parent = {child = "child_value"}
    list_field = ["first", "second", "third"]

# Accepts and outputs `metric` events allowing you to add one or more metric tags.
[transforms.add_tags]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "add_tags"
  type = "add_tags"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  #
  # Tags
  #

  [transforms.add_tags.tags]
    # The name of the tag to add. Due to the nature of metric tags, the value must
    # be a string.
    #
    # * required
    # * type: string
    static_tag = "my value"
    env_tag = "${ENV_VAR}"

# Accepts and outputs `log` events allowing you to strips ANSI escape sequences from the specified field.
[transforms.ansi_stripper]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "ansi_stripper"
  type = "ansi_stripper"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The target field to strip ANSI escape sequences from.
  #
  # * required
  # * default: "message"
  # * type: string
  field = "message"

# Accepts and outputs `log` events allowing you to enrich logs with AWS EC2 instance metadata.
[transforms.aws_ec2_metadata]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "aws_ec2_metadata"
  type = "aws_ec2_metadata"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # A list of fields to include in each event.
  #
  # * optional
  # * default: ["instance-id", "local-hostname", "local-ipv4", "public-hostname", "public-ipv4", "ami-id", "availability-zone", "vpc-id", "subnet-id", "region"]
  # * type: [string]
  fields = ["instance-id", "local-hostname", "local-ipv4", "public-hostname", "public-ipv4", "ami-id", "availability-zone", "vpc-id", "subnet-id", "region"]

  # Override the default EC2 Metadata host.
  #
  # * optional
  # * default: "http://169.254.169.254"
  # * type: string
  host = "http://169.254.169.254"

  # Prepend a namespace to each field's key.
  #
  # * optional
  # * default: ""
  # * type: string
  namespace = ""

  # The interval in seconds at which the EC2 Metadata api will be called.
  #
  # * optional
  # * default: 10
  # * type: int
  refresh_interval_secs = 10

# Accepts and outputs `log` events allowing you to coerce log fields into fixed types.
[transforms.coercer]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "coercer"
  type = "coercer"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # Set to `true` to drop all fields that are not specified in the `types` table.
  # Make sure both `message` and `timestamp` are specified in the `types` table
  # as their absense will cause the original message data to be dropped along
  # with other extraneous fields.
  #
  # * optional
  # * default: false
  # * type: bool
  drop_unspecified = false
  drop_unspecified = true

  #
  # Types
  #

  [transforms.coercer.types]
    # A definition of log field type conversions. They key is the log field name
    # and the value is the type. `strptime` specifiers are supported for the
    # `timestamp` type.
    #
    # * optional
    # * no default
    # * type: string
    # * enum: "bool", "float", "int", "string", and "timestamp"
    status = "int"
    duration = "float"
    success = "bool"
    timestamp = "timestamp|%F"
    timestamp = "timestamp|%a %b %e %T %Y"

# Accepts and outputs `log` events allowing you to concat (substrings) of other fields to a new one.
[transforms.concat]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "concat"
  type = "concat"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # A list of substring definitons in the format of source_field[start..end]. For
  # both start and end negative values are counted from the end of the string.
  #
  # * required
  # * type: [string]
  items = ["first[..3]", "second[-5..]", "third[3..6]"]

  # The string that is used to join all items.
  #
  # * required
  # * default: " "
  # * type: string
  joiner = " "
  joiner = ","
  joiner = "_"
  joiner = "+"

  # The name for the new label.
  #
  # * required
  # * type: string
  target = "dest_field_name"

# Accepts and outputs `log` events allowing you to filter events by a log field's value.
[transforms.field_filter]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "field_filter"
  type = "field_filter"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The target log field to compare against the `value`.
  #
  # * required
  # * type: string
  field = "file"

  # If the value of the specified `field` matches this value then the event will
  # be permitted, otherwise it is dropped.
  #
  # * required
  # * type: string
  value = "/var/log/nginx.log"

# Accepts and outputs `log` events allowing you to enrich events with geolocation data from the MaxMind GeoIP2 and GeoLite2 city databases.
[transforms.geoip]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "geoip"
  type = "geoip"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # Path to the MaxMind GeoIP2 or GeoLite2 binary city database file
  # (`GeoLite2-City.mmdb`). Other databases, such as the the country database are
  # not supported.
  #
  # * required
  # * type: string
  database = "/path/to/GeoLite2-City.mmdb"

  # The field name that contains the IP address. This field should contain a
  # valid IPv4 or IPv6 address.
  #
  # * required
  # * type: string
  source = "ip_address"
  source = "x-forwarded-for"

  # The default field to insert the resulting GeoIP data into. See output for
  # more info.
  #
  # * required
  # * default: "geoip"
  # * type: string
  target = "geoip"

# Accepts and outputs `log` events allowing you to parse a log field value with Grok.
[transforms.grok_parser]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "grok_parser"
  type = "grok_parser"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # If `true` will drop the specified `field` after parsing.
  #
  # * required
  # * default: true
  # * type: bool
  drop_field = true
  drop_field = false

  # The log field to execute the `pattern` against. Must be a `string` value.
  #
  # * required
  # * default: "message"
  # * type: string
  field = "message"

  # The Grok pattern
  #
  # * required
  # * type: string
  pattern = "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{GREEDYDATA:message}"

  #
  # Types
  #

  [transforms.grok_parser.types]
    # A definition of log field type conversions. They key is the log field name
    # and the value is the type. `strptime` specifiers are supported for the
    # `timestamp` type.
    #
    # * optional
    # * no default
    # * type: string
    # * enum: "bool", "float", "int", "string", and "timestamp"
    status = "int"
    duration = "float"
    success = "bool"
    timestamp = "timestamp|%F"
    timestamp = "timestamp|%a %b %e %T %Y"

# Accepts and outputs `log` events allowing you to parse a log field value as JSON.
[transforms.json_parser]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "json_parser"
  type = "json_parser"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # If the specified `field` should be dropped (removed) after parsing. If
  # parsing fails, the field will not be removed, irrespective of this setting.
  #
  # * required
  # * default: true
  # * type: bool
  drop_field = true
  drop_field = false

  # If `true` events with invalid JSON will be dropped, otherwise the event will
  # be kept and passed through.
  #
  # * required
  # * type: bool
  drop_invalid = true

  # The log field to decode as JSON. Must be a `string` value type.
  #
  # * required
  # * default: "message"
  # * type: string
  field = "message"

  # If `target_field` is set and the log contains a field of the same name as the
  # target, it will only be overwritten if this is set to `true`.
  #
  # * optional
  # * default: false
  # * type: bool
  overwrite_target = false
  overwrite_target = true

  # If this setting is present, the parsed JSON will be inserted into the log as
  # a sub-object with this name. If a field with the same name already exists,
  # the parser will fail and produce an error.
  #
  # * optional
  # * no default
  # * type: string
  target_field = "target"

# Accepts `log` events but outputs `metric` events allowing you to convert logs into one or more metrics.
[transforms.log_to_metric]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "log_to_metric"
  type = "log_to_metric"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  #
  # Metrics
  #

  [[transforms.log_to_metric.metrics]]
    # The metric type.
    #
    # * required
    # * type: string
    # * enum: "counter", "gauge", "histogram", and "set"
    type = "counter"
    type = "gauge"
    type = "histogram"
    type = "set"

    # The log field to use as the metric.
    #
    # * required
    # * type: string
    field = "duration"

    # If `true` the metric will be incremented by the `field` value. If `false` the
    # metric will be incremented by 1 regardless of the `field` value.
    #
    # * required
    # * default: false
    # * type: bool
    # * relevant when type = "counter"
    increment_by_value = false
    increment_by_value = true

    # The name of the metric. Defaults to `<field>_total` for `counter` and
    # `<field>` for `gauge`.
    #
    # * required
    # * type: string
    name = "duration_total"

    [transforms.log_to_metric.metrics.tags]
      # Key/value pairs representing metric tags. Environment variables and field
      # interpolation is allowed.
      #
      # * required
      # * type: string
      host = "${HOSTNAME}"
      region = "us-east-1"
      status = "{{status}}"

# Accepts and outputs `log` events allowing you to extract data from a logfmt-formatted log field.
[transforms.logfmt_parser]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "logfmt_parser"
  type = "logfmt_parser"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # If the specified `field` should be dropped (removed) after parsing.
  #
  # * required
  # * default: true
  # * type: bool
  drop_field = true
  drop_field = false

  # The log field to parse.
  #
  # * required
  # * default: "message"
  # * type: string
  field = "message"

  #
  # Types
  #

  [transforms.logfmt_parser.types]
    # A definition of log field type conversions. They key is the log field name
    # and the value is the type. `strptime` specifiers are supported for the
    # `timestamp` type.
    #
    # * optional
    # * no default
    # * type: string
    # * enum: "bool", "float", "int", "string", and "timestamp"
    status = "int"
    duration = "float"
    success = "bool"
    timestamp = "timestamp|%F"
    timestamp = "timestamp|%a %b %e %T %Y"

# Accepts and outputs `log` events allowing you to transform events with a full embedded Lua engine.
[transforms.lua]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "lua"
  type = "lua"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The inline Lua source to evaluate.
  #
  # * required
  # * type: string
  source = """
require("script") # a `script.lua` file must be in your `search_dirs`

if event["host"] == nil then
  local f = io.popen ("/bin/hostname")
  local hostname = f:read("*a") or ""
  f:close()
  hostname = string.gsub(hostname, "\n$", "")
  event["host"] = hostname
end
"""

  # A list of directories search when loading a Lua file via the `require`
  # function.
  #
  # * optional
  # * no default
  # * type: [string]
  search_dirs = ["/etc/vector/lua"]

# Accepts and outputs `log` events allowing you to merge partial log events into a single event.
[transforms.merge]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "merge"
  type = "merge"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # Fields to merge. The values of these fields will be merged into the first
  # partial event. Fields not specified here will be ignored. Merging process
  # takes the first partial event and the base, then it merges in the fields from
  # each successive partial event, until a non-partial event arrives. Finally,
  # the non-partial event fields are merged in, producing the resulting merged
  # event.
  #
  # * optional
  # * default: ["message"]
  # * type: [string]
  merge_fields = ["message"]

  # The field that indicates that the event is partial. A consequent stream of
  # partial events along with the first non-partial event will be merged together.
  #
  # * optional
  # * default: "_partial"
  # * type: string
  partial_event_marker_field = "_partial"

  # An ordered list of fields to distinguish streams by. Each stream has a
  # separate partial event merging state. Should be used to prevent events from
  # unrelated sources from mixing together, as this affects partial event
  # processing.
  #
  # * optional
  # * default: []
  # * type: [string]
  stream_discriminant_fields = []

# Accepts and outputs `log` events allowing you to parse a log field's value with a Regular Expression.
[transforms.regex_parser]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "regex_parser"
  type = "regex_parser"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # If the specified `field` should be dropped (removed) after parsing.
  #
  # * required
  # * default: true
  # * type: bool
  drop_field = true
  drop_field = false

  # The log field to parse.
  #
  # * required
  # * default: "message"
  # * type: string
  field = "message"

  # The Regular Expression to apply. Do not include the leading or trailing `/`.
  #
  # * required
  # * type: string
  regex = "^(?P<timestamp>[\\w\\-:\\+]+) (?P<level>\\w+) (?P<message>.*)$"

  #
  # Types
  #

  [transforms.regex_parser.types]
    # A definition of log field type conversions. They key is the log field name
    # and the value is the type. `strptime` specifiers are supported for the
    # `timestamp` type.
    #
    # * optional
    # * no default
    # * type: string
    # * enum: "bool", "float", "int", "string", and "timestamp"
    status = "int"
    duration = "float"
    success = "bool"
    timestamp = "timestamp|%F"
    timestamp = "timestamp|%a %b %e %T %Y"

# Accepts and outputs `log` events allowing you to remove one or more log fields.
[transforms.remove_fields]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "remove_fields"
  type = "remove_fields"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The log field names to drop.
  #
  # * required
  # * type: [string]
  fields = ["field1", "field2"]

# Accepts and outputs `metric` events allowing you to remove one or more metric tags.
[transforms.remove_tags]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "remove_tags"
  type = "remove_tags"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The tag names to drop.
  #
  # * required
  # * type: [string]
  tags = ["tag1", "tag2"]

# Accepts and outputs `log` events allowing you to rename one or more log fields.
[transforms.rename_fields]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "rename_fields"
  type = "rename_fields"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  #
  # Fields
  #

  [transforms.rename_fields.fields]
    # The name of the field to move. Use `.` for adding nested fields.
    #
    # * required
    # * type: *
    old field name = "new field name"

# Accepts and outputs `log` events allowing you to sample events with a configurable rate.
[transforms.sampler]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "sampler"
  type = "sampler"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The rate at which events will be forwarded, expressed as 1/N. For example,
  # `rate = 10` means 1 out of every 10 events will be forwarded and the rest
  # will be dropped.
  #
  # * required
  # * type: int
  rate = 10

  # A list of regular expression patterns to exclude events from sampling. If an
  # event's `"message"` key matches _any_ of these patterns it will _not_ be
  # sampled.
  #
  # * optional
  # * no default
  # * type: [string]
  pass_list = ["[error]", "field2"]

# Accepts and outputs `log` events allowing you to split a field's value on a _literal_ separator and zip the tokens into ordered field names.
[transforms.split]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "split"
  type = "split"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # If `true` the `field` will be dropped after parsing.
  #
  # * required
  # * default: true
  # * type: bool
  drop_field = true
  drop_field = false

  # The field to apply the split on.
  #
  # * required
  # * default: "message"
  # * type: string
  field = "message"

  # The field names assigned to the resulting tokens, in order.
  #
  # * required
  # * type: [string]
  field_names = ["timestamp", "level", "message"]

  # The separator to split the field on. If no separator is given, it will split
  # on all whitespace. 'Whitespace' is defined according to the terms of the
  # Unicode Derived Core Property `White_Space`.
  #
  # * required
  # * default: "[whitespace]"
  # * type: [string]
  separator = ","

  #
  # Types
  #

  [transforms.split.types]
    # A definition of log field type conversions. They key is the log field name
    # and the value is the type. `strptime` specifiers are supported for the
    # `timestamp` type.
    #
    # * optional
    # * no default
    # * type: string
    # * enum: "bool", "float", "int", "string", and "timestamp"
    status = "int"
    duration = "float"
    success = "bool"
    timestamp = "timestamp|%F"
    timestamp = "timestamp|%a %b %e %T %Y"

# Accepts and outputs `log` events allowing you to route events across parallel streams using logical filters.
[transforms.swimlanes]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "swimlanes"
  type = "swimlanes"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  #
  # Lanes
  #

  [transforms.swimlanes.lanes]
    [transforms.swimlanes.lanes.`<swimlane_id>`]
      # The type of the condition to execute. Currently only the `check_fields` type
      # is available.
      #
      # * required
      # * type: string
      type = "check_fields"

      # Check whether a fields contents exactly matches the value specified.
      #
      # * optional
      # * no default
      # * type: string
      "message.eq" = "this is the content to match against"

      # Check whether a field exists or does not exist, depending on the provided
      # valuebeing `true` or `false` respectively.
      #
      # * optional
      # * no default
      # * type: bool
      "host.exists" = true

      # Check whether a fields contents does not match the value specified.
      #
      # * optional
      # * no default
      # * type: string
      "method.neq" = "POST"

# Accepts and outputs `log` events allowing you to tokenize a field's value by splitting on white space, ignoring special wrapping characters, and zip the tokens into ordered field names.
[transforms.tokenizer]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "tokenizer"
  type = "tokenizer"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # If `true` the `field` will be dropped after parsing.
  #
  # * required
  # * default: true
  # * type: bool
  drop_field = true
  drop_field = false

  # The log field to tokenize.
  #
  # * required
  # * default: "message"
  # * type: string
  field = "message"

  # The log field names assigned to the resulting tokens, in order.
  #
  # * required
  # * type: [string]
  field_names = ["timestamp", "level", "message"]

  #
  # Types
  #

  [transforms.tokenizer.types]
    # A definition of log field type conversions. They key is the log field name
    # and the value is the type. `strptime` specifiers are supported for the
    # `timestamp` type.
    #
    # * optional
    # * no default
    # * type: string
    # * enum: "bool", "float", "int", "string", and "timestamp"
    status = "int"
    duration = "float"
    success = "bool"
    timestamp = "timestamp|%F"
    timestamp = "timestamp|%a %b %e %T %Y"


# ------------------------------------------------------------------------------
# Sinks
# ------------------------------------------------------------------------------
# Sinks batch or stream data out of Vector.

# Batches `log` events to Amazon Web Service's CloudWatch Logs service via the `PutLogEvents` API endpoint.
[sinks.aws_cloudwatch_logs]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "aws_cloudwatch_logs"
  type = "aws_cloudwatch_logs"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The group name of the target CloudWatch Logs stream.
  #
  # * required
  # * type: string
  group_name = "{{ file }}"
  group_name = "ec2/{{ instance_id }}"
  group_name = "group-name"

  # The AWS region of the target service. If `endpoint` is provided it will
  # override this value since the endpoint includes the region.
  #
  # * required
  # * type: string
  # * relevant when host = ""
  region = "us-east-1"

  # The stream name of the target CloudWatch Logs stream.
  #
  # * required
  # * type: string
  stream_name = "{{ instance_id }}"
  stream_name = "%Y-%m-%d"
  stream_name = "stream-name"

  # The ARN of an IAM role to assume at startup.
  #
  # * optional
  # * no default
  # * type: string
  assume_role = "arn:aws:iam::123456789098:role/my_role"

  # Dynamically create a log group if it does not already exist. This will ignore
  # `create_missing_stream` directly after creating the group and will create the
  # first stream.
  #
  # * optional
  # * default: true
  # * type: bool
  create_missing_group = true
  create_missing_group = false

  # Dynamically create a log stream if it does not already exist.
  #
  # * optional
  # * default: true
  # * type: bool
  create_missing_stream = true
  create_missing_stream = false

  # Custom endpoint for use with AWS-compatible services. Providing a value for
  # this option will make `region` moot.
  #
  # * optional
  # * no default
  # * type: string
  # * relevant when region = ""
  endpoint = "127.0.0.0:5000/path/to/service"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  #
  # requests
  #

  # The encoding format used to serialize the events before outputting.
  #
  # * required
  # * type: string
  # * enum: "json" or "text"
  encoding = "json"
  encoding = "text"

  #
  # Batch
  #

  [sinks.aws_cloudwatch_logs.batch]
    # The maximum size of a batch, in bytes, before it is flushed.
    #
    # * required
    # * default: 1049000
    # * type: int
    # * unit: bytes
    max_size = 1049000

    # The maximum age of a batch before it is flushed.
    #
    # * required
    # * default: 1
    # * type: int
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.aws_cloudwatch_logs.buffer]
    # The buffer's type and storage mechanism.
    #
    # * required
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * required
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Request
  #

  [sinks.aws_cloudwatch_logs.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: int
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 5
    # * type: int
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: -1
    # * type: int
    retry_attempts = -1

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 30
    # * type: int
    # * unit: seconds
    timeout_secs = 30

# Streams `metric` events to Amazon Web Service's CloudWatch Metrics service via the `PutMetricData` API endpoint.
[sinks.aws_cloudwatch_metrics]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "aws_cloudwatch_metrics"
  type = "aws_cloudwatch_metrics"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # A namespace that will isolate different metrics from each other.
  #
  # * required
  # * type: string
  namespace = "service"

  # The AWS region of the target service. If `endpoint` is provided it will
  # override this value since the endpoint includes the region.
  #
  # * required
  # * type: string
  # * relevant when host = ""
  region = "us-east-1"

  # The ARN of an IAM role to assume at startup.
  #
  # * optional
  # * no default
  # * type: string
  assume_role = "arn:aws:iam::123456789098:role/my_role"

  # Custom endpoint for use with AWS-compatible services. Providing a value for
  # this option will make `region` moot.
  #
  # * optional
  # * no default
  # * type: string
  # * relevant when region = ""
  endpoint = "127.0.0.0:5000/path/to/service"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  #
  # Batch
  #

  [sinks.aws_cloudwatch_metrics.batch]
    # The maximum size of a batch, in events, before it is flushed.
    #
    # * required
    # * default: 20
    # * type: int
    # * unit: events
    max_events = 20

    # The maximum age of a batch before it is flushed.
    #
    # * required
    # * default: 1
    # * type: int
    # * unit: seconds
    timeout_secs = 1

# Batches `log` events to Amazon Web Service's Kinesis Data Firehose via the `PutRecordBatch` API endpoint.
[sinks.aws_kinesis_firehose]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "aws_kinesis_firehose"
  type = "aws_kinesis_firehose"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The AWS region of the target service. If `endpoint` is provided it will
  # override this value since the endpoint includes the region.
  #
  # * required
  # * type: string
  # * relevant when host = ""
  region = "us-east-1"

  # The stream name of the target Kinesis Firehose delivery stream.
  #
  # * required
  # * type: string
  stream_name = "my-stream"

  # The ARN of an IAM role to assume at startup.
  #
  # * optional
  # * no default
  # * type: string
  assume_role = "arn:aws:iam::123456789098:role/my_role"

  # Custom endpoint for use with AWS-compatible services. Providing a value for
  # this option will make `region` moot.
  #
  # * optional
  # * no default
  # * type: string
  # * relevant when region = ""
  endpoint = "127.0.0.0:5000/path/to/service"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  #
  # requests
  #

  # The encoding format used to serialize the events before outputting.
  #
  # * required
  # * type: string
  # * enum: "json" or "text"
  encoding = "json"
  encoding = "text"

  #
  # Batch
  #

  [sinks.aws_kinesis_firehose.batch]
    # The maximum size of a batch, in events, before it is flushed.
    #
    # * required
    # * default: 500
    # * type: int
    # * unit: events
    max_events = 500

    # The maximum age of a batch before it is flushed.
    #
    # * required
    # * default: 1
    # * type: int
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.aws_kinesis_firehose.buffer]
    # The buffer's type and storage mechanism.
    #
    # * required
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * required
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Request
  #

  [sinks.aws_kinesis_firehose.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: int
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 5
    # * type: int
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: -1
    # * type: int
    retry_attempts = -1

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 30
    # * type: int
    # * unit: seconds
    timeout_secs = 30

# Batches `log` events to Amazon Web Service's Kinesis Data Stream service via the `PutRecords` API endpoint.
[sinks.aws_kinesis_streams]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "aws_kinesis_streams"
  type = "aws_kinesis_streams"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The AWS region of the target service. If `endpoint` is provided it will
  # override this value since the endpoint includes the region.
  #
  # * required
  # * type: string
  # * relevant when host = ""
  region = "us-east-1"

  # The stream name of the target Kinesis Logs stream.
  #
  # * required
  # * type: string
  stream_name = "my-stream"

  # The ARN of an IAM role to assume at startup.
  #
  # * optional
  # * no default
  # * type: string
  assume_role = "arn:aws:iam::123456789098:role/my_role"

  # Custom endpoint for use with AWS-compatible services. Providing a value for
  # this option will make `region` moot.
  #
  # * optional
  # * no default
  # * type: string
  # * relevant when region = ""
  endpoint = "127.0.0.0:5000/path/to/service"

  # The log field used as the Kinesis record's partition key value.
  #
  # * optional
  # * no default
  # * type: string
  partition_key_field = "user_id"

  #
  # requests
  #

  # The encoding format used to serialize the events before outputting.
  #
  # * required
  # * type: string
  # * enum: "json" or "text"
  encoding = "json"
  encoding = "text"

  #
  # Batch
  #

  [sinks.aws_kinesis_streams.batch]
    # The maximum size of a batch, in events, before it is flushed.
    #
    # * required
    # * default: 500
    # * type: int
    # * unit: events
    max_events = 500

    # The maximum age of a batch before it is flushed.
    #
    # * required
    # * default: 1
    # * type: int
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.aws_kinesis_streams.buffer]
    # The buffer's type and storage mechanism.
    #
    # * required
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * required
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Request
  #

  [sinks.aws_kinesis_streams.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: int
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 5
    # * type: int
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: -1
    # * type: int
    retry_attempts = -1

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 30
    # * type: int
    # * unit: seconds
    timeout_secs = 30

# Batches `log` events to Amazon Web Service's S3 service via the `PutObject` API endpoint.
[sinks.aws_s3]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "aws_s3"
  type = "aws_s3"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The S3 bucket name. Do not include a leading `s3://` or a trailing `/`.
  #
  # * required
  # * type: string
  bucket = "my-bucket"

  # The compression mechanism to use.
  #
  # * required
  # * type: string
  # * enum: "gzip" or "none"
  compression = "gzip"
  compression = "none"

  # The AWS region of the target service. If `endpoint` is provided it will
  # override this value since the endpoint includes the region.
  #
  # * required
  # * type: string
  # * relevant when host = ""
  region = "us-east-1"

  # The ARN of an IAM role to assume at startup.
  #
  # * optional
  # * no default
  # * type: string
  assume_role = "arn:aws:iam::123456789098:role/my_role"

  # Custom endpoint for use with AWS-compatible services. Providing a value for
  # this option will make `region` moot.
  #
  # * optional
  # * no default
  # * type: string
  # * relevant when region = ""
  endpoint = "127.0.0.0:5000/path/to/service"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  #
  # Object Names
  #

  # Whether or not to append a UUID v4 token to the end of the file. This ensures
  # there are no name collisions high volume use cases.
  #
  # * required
  # * default: true
  # * type: bool
  filename_append_uuid = true
  filename_append_uuid = false

  # The filename extension to use in the object name.
  #
  # * required
  # * default: "log"
  # * type: string
  filename_extension = "log"

  # The format of the resulting object file name. `strftime` specifiers are
  # supported.
  #
  # * required
  # * default: "%s"
  # * type: string
  filename_time_format = "%s"

  # A prefix to apply to all object key names. This should be used to partition
  # your objects, and it's important to end this value with a `/` if you want
  # this to be the root S3 "folder".
  #
  # * optional
  # * default: "date=%F/"
  # * type: string
  key_prefix = "date=%F/"
  key_prefix = "date=%F/hour=%H/"
  key_prefix = "year=%Y/month=%m/day=%d/"
  key_prefix = "application_id={{ application_id }}/date=%F/"

  #
  # requests
  #

  # The encoding format used to serialize the events before outputting.
  #
  # * required
  # * type: string
  # * enum: "ndjson" or "text"
  encoding = "ndjson"
  encoding = "text"

  #
  # Object Attributes
  #

  # Canned ACL to apply to the created objects. For more information, see Canned
  # ACL.
  #
  # * optional
  # * no default
  # * type: string
  # * enum: "private", "public-read", "public-read-write", "aws-exec-read", "authenticated-read", and "log-delivery-write"
  acl = "private"
  acl = "public-read"
  acl = "public-read-write"
  acl = "aws-exec-read"
  acl = "authenticated-read"
  acl = "log-delivery-write"

  # Gives the named grantee READ, READ_ACP, and WRITE_ACP permissions on the
  # created objects.
  #
  # * optional
  # * no default
  # * type: string
  grant_full_control = "79a59df900b949e55d96a1e698fbacedfd6e09d98eacf8f8d5218e7cd47ef2be"
  grant_full_control = "person@email.com"
  grant_full_control = "http://acs.amazonaws.com/groups/global/AllUsers"

  # Allows the named grantee to read the created objects and their metadata.
  #
  # * optional
  # * no default
  # * type: string
  grant_read = "79a59df900b949e55d96a1e698fbacedfd6e09d98eacf8f8d5218e7cd47ef2be"
  grant_read = "person@email.com"
  grant_read = "http://acs.amazonaws.com/groups/global/AllUsers"

  # Allows the named grantee to read the created objects' ACL.
  #
  # * optional
  # * no default
  # * type: string
  grant_read_acp = "79a59df900b949e55d96a1e698fbacedfd6e09d98eacf8f8d5218e7cd47ef2be"
  grant_read_acp = "person@email.com"
  grant_read_acp = "http://acs.amazonaws.com/groups/global/AllUsers"

  # Allows the named grantee to write the created objects' ACL.
  #
  # * optional
  # * no default
  # * type: string
  grant_write_acp = "79a59df900b949e55d96a1e698fbacedfd6e09d98eacf8f8d5218e7cd47ef2be"
  grant_write_acp = "person@email.com"
  grant_write_acp = "http://acs.amazonaws.com/groups/global/AllUsers"

  # The server-side encryption algorithm used when storing these objects.
  #
  # * optional
  # * no default
  # * type: string
  # * enum: "AES256" or "aws:kms"
  server_side_encryption = "AES256"
  server_side_encryption = "aws:kms"

  # If `server_side_encryption` has the value `"aws.kms"`, this specifies the ID
  # of the AWS Key Management Service (AWS KMS) symmetrical customer managed
  # customer master key (CMK) that will used for the created objects. If not
  # specified, Amazon S3 uses the AWS managed CMK in AWS to protect the data.
  #
  # * optional
  # * no default
  # * type: string
  ssekms_key_id = "abcd1234"

  # The storage class for the created objects. See the S3 Storage Classes for
  # more details.
  #
  # * optional
  # * no default
  # * type: string
  # * enum: "STANDARD", "REDUCED_REDUNDANCY", "INTELLIGENT_TIERING", "STANDARD_IA", "ONEZONE_IA", "GLACIER", and "DEEP_ARCHIVE"
  storage_class = "STANDARD"
  storage_class = "REDUCED_REDUNDANCY"
  storage_class = "INTELLIGENT_TIERING"
  storage_class = "STANDARD_IA"
  storage_class = "ONEZONE_IA"
  storage_class = "GLACIER"
  storage_class = "DEEP_ARCHIVE"

  [sinks.aws_s3.tags]
    # A custom tag to be added to the created objects.
    #
    # * optional
    # * no default
    # * type: string
    Tag1 = "Value1"

  #
  # Batch
  #

  [sinks.aws_s3.batch]
    # The maximum size of a batch, in bytes, before it is flushed.
    #
    # * required
    # * default: 10490000
    # * type: int
    # * unit: bytes
    max_size = 10490000

    # The maximum age of a batch before it is flushed.
    #
    # * required
    # * default: 300
    # * type: int
    # * unit: seconds
    timeout_secs = 300

  #
  # Buffer
  #

  [sinks.aws_s3.buffer]
    # The buffer's type and storage mechanism.
    #
    # * required
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * required
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Request
  #

  [sinks.aws_s3.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: int
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 5
    # * type: int
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: -1
    # * type: int
    retry_attempts = -1

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 30
    # * type: int
    # * unit: seconds
    timeout_secs = 30

# Streams `log` and `metric` events to a blackhole that simply discards data, designed for testing and benchmarking purposes.
[sinks.blackhole]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "blackhole"
  type = "blackhole"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The number of events that must be received in order to print a summary of
  # activity.
  #
  # * required
  # * type: int
  print_amount = 1000

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

# Batches `log` events to Clickhouse via the `HTTP` Interface.
[sinks.clickhouse]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "clickhouse"
  type = "clickhouse"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The host url of the Clickhouse server.
  #
  # * required
  # * type: string
  host = "http://localhost:8123"

  # The table that data will be inserted into.
  #
  # * required
  # * type: string
  table = "mytable"

  # The database that contains the stable that data will be inserted into.
  #
  # * optional
  # * no default
  # * type: string
  database = "mydatabase"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  #
  # requests
  #

  # The compression strategy used to compress the encoded event data before
  # outputting.
  #
  # * optional
  # * default: "none"
  # * type: string
  # * enum: "none" or "gzip"
  compression = "none"
  compression = "gzip"

  #
  # Auth
  #

  [sinks.clickhouse.auth]
    # The authentication strategy to use.
    #
    # * required
    # * type: string
    # * must be: "basic"
    strategy = "basic"

    # The basic authentication password.
    #
    # * required
    # * type: string
    # * relevant when strategy = "basic"
    password = "${PASSWORD_ENV_VAR}"
    password = "password"

    # The basic authentication user name.
    #
    # * required
    # * type: string
    # * relevant when strategy = "basic"
    user = "${USERNAME_ENV_VAR}"
    user = "username"

  #
  # Batch
  #

  [sinks.clickhouse.batch]
    # The maximum size of a batch, in bytes, before it is flushed.
    #
    # * required
    # * default: 1049000
    # * type: int
    # * unit: bytes
    max_size = 1049000

    # The maximum age of a batch before it is flushed.
    #
    # * required
    # * default: 1
    # * type: int
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.clickhouse.buffer]
    # The buffer's type and storage mechanism.
    #
    # * required
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * required
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Encoding
  #

  [sinks.clickhouse.encoding]
    # How to format event timestamps. Formats such as unix can be parsed as a
    # Clickhouse DateTime, however, this loses precision as DateTimes are defined
    # in seconds.
    #
    # * optional
    # * default: "rfc3339"
    # * type: string
    # * enum: "rfc3339" or "unix"
    timestamp_format = "rfc3339"
    timestamp_format = "unix"
    timestamp_format = "unix_ms"


  #
  # Request
  #

  [sinks.clickhouse.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: int
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 5
    # * type: int
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: -1
    # * type: int
    retry_attempts = -1

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 30
    # * type: int
    # * unit: seconds
    timeout_secs = 30

  #
  # Tls
  #

  [sinks.clickhouse.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509).
    #
    # * optional
    # * no default
    # * type: string
    ca_path = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12. If this is set and is not a PKCS#12
    # archive, `key_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_path = "/path/to/host_certificate.crt"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_path` is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

    # Absolute path to a certificate key file used to identify this connection, in
    # DER or PEM format (PKCS#8). If this is set, `crt_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_path = "/path/to/host_certificate.key"

    # If `true` (the default), Vector will validate the TLS certificate of the
    # remote host. Do NOT set this to `false` unless you understand the risks of
    # not verifying the remote certificate.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_certificate = true
    verify_certificate = false

    # If `true` (the default), Vector will validate the configured remote host name
    # against the remote host's TLS certificate. Do NOT set this to `false` unless
    # you understand the risks of not verifying the remote hostname.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_hostname = true
    verify_hostname = false

# Streams `log` and `metric` events to standard output streams, such as `STDOUT` and `STDERR`.
[sinks.console]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "console"
  type = "console"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The standard stream to write to.
  #
  # * required
  # * default: "stdout"
  # * type: string
  # * enum: "stdout" or "stderr"
  target = "stdout"
  target = "stderr"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  #
  # requests
  #

  # The encoding format used to serialize the events before outputting.
  #
  # * required
  # * type: string
  # * enum: "json" or "text"
  encoding = "json"
  encoding = "text"

# Batches `metric` events to Datadog's metrics service using HTTP API.
[sinks.datadog_metrics]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "datadog_metrics"
  type = "datadog_metrics"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # Datadog API key
  #
  # * required
  # * type: string
  api_key = "${DATADOG_API_KEY_ENV_VAR}"
  api_key = "ef8d5de700e7989468166c40fc8a0ccd"

  # A prefix that will be added to all metric names.
  #
  # * required
  # * type: string
  namespace = "service"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # Datadog endpoint to send metrics to.
  #
  # * optional
  # * default: "https://api.datadoghq.com"
  # * type: string
  host = "https://api.datadoghq.com"
  host = "https://api.datadoghq.eu"

  #
  # Batch
  #

  [sinks.datadog_metrics.batch]
    # The maximum size of a batch, in events, before it is flushed.
    #
    # * required
    # * default: 20
    # * type: int
    # * unit: events
    max_events = 20

    # The maximum age of a batch before it is flushed.
    #
    # * required
    # * default: 1
    # * type: int
    # * unit: seconds
    timeout_secs = 1

  #
  # Request
  #

  [sinks.datadog_metrics.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: int
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 5
    # * type: int
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: -1
    # * type: int
    retry_attempts = -1

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: int
    # * unit: seconds
    timeout_secs = 60

# Batches `log` events to Elasticsearch via the `_bulk` API endpoint.
[sinks.elasticsearch]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "elasticsearch"
  type = "elasticsearch"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The `doc_type` for your index data. This is only relevant for Elasticsearch
  # <= 6.X. If you are using >= 7.0 you do not need to set this option since
  # Elasticsearch has removed it.
  #
  # * required
  # * default: "_doc"
  # * type: string
  doc_type = "_doc"

  # Index name to write events to.
  #
  # * required
  # * default: "vector-%F"
  # * type: string
  index = "application-{{ application_id }}-%Y-%m-%d"
  index = "vector-%Y-%m-%d"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # The host of your Elasticsearch cluster. This should be the full URL as shown
  # in the example.
  #
  # * optional
  # * no default
  # * type: string
  host = "http://10.24.32.122:9000"

  #
  # Auth
  #

  [sinks.elasticsearch.auth]
    # The authentication strategy to use.
    #
    # * required
    # * type: string
    # * enum: "aws" or "basic"
    strategy = "aws"
    strategy = "basic"

    # The basic authentication password.
    #
    # * required
    # * type: string
    # * relevant when strategy = "basic"
    password = "${PASSWORD_ENV_VAR}"
    password = "password"

    # The basic authentication user name.
    #
    # * required
    # * type: string
    # * relevant when strategy = "basic"
    user = "${USERNAME_ENV_VAR}"
    user = "username"

  #
  # Batch
  #

  [sinks.elasticsearch.batch]
    # The maximum size of a batch, in bytes, before it is flushed.
    #
    # * required
    # * default: 10490000
    # * type: int
    # * unit: bytes
    max_size = 10490000

    # The maximum age of a batch before it is flushed.
    #
    # * required
    # * default: 1
    # * type: int
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.elasticsearch.buffer]
    # The buffer's type and storage mechanism.
    #
    # * required
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * required
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Headers
  #

  [sinks.elasticsearch.headers]
    # A custom header to be added to each outgoing Elasticsearch request.
    #
    # * required
    # * type: string
    Authorization = "${TOKEN_ENV_VAR}"
    X-Powered-By = "Vector"

  #
  # Query
  #

  [sinks.elasticsearch.query]
    # A custom parameter to be added to each Elasticsearch request.
    #
    # * required
    # * type: string
    X-Powered-By = "Vector"

  #
  # Request
  #

  [sinks.elasticsearch.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: int
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 5
    # * type: int
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: -1
    # * type: int
    retry_attempts = -1

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: int
    # * unit: seconds
    timeout_secs = 60

  #
  # Tls
  #

  [sinks.elasticsearch.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509).
    #
    # * optional
    # * no default
    # * type: string
    ca_path = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12. If this is set and is not a PKCS#12
    # archive, `key_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_path = "/path/to/host_certificate.crt"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_path` is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

    # Absolute path to a certificate key file used to identify this connection, in
    # DER or PEM format (PKCS#8). If this is set, `crt_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_path = "/path/to/host_certificate.key"

    # If `true` (the default), Vector will validate the TLS certificate of the
    # remote host. Do NOT set this to `false` unless you understand the risks of
    # not verifying the remote certificate.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_certificate = true
    verify_certificate = false

    # If `true` (the default), Vector will validate the configured remote host name
    # against the remote host's TLS certificate. Do NOT set this to `false` unless
    # you understand the risks of not verifying the remote hostname.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_hostname = true
    verify_hostname = false

# Streams `log` events to a file.
[sinks.file]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "file"
  type = "file"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # File name to write events to.
  #
  # * required
  # * type: string
  path = "vector-%Y-%m-%d.log"
  path = "application-{{ application_id }}-%Y-%m-%d.log"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # The amount of time a file can be idle  and stay open. After not receiving any
  # events for this timeout, the file will be flushed and closed.
  #
  # * optional
  # * default: "30"
  # * type: int
  idle_timeout_secs = "30"

  #
  # requests
  #

  # The encoding format used to serialize the events before outputting.
  #
  # * required
  # * type: string
  # * enum: "ndjson" or "text"
  encoding = "ndjson"
  encoding = "text"

# Batches `log` events to Google Cloud Platform's Cloud Storage service via the XML Interface.
[sinks.gcp_cloud_storage]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "gcp_cloud_storage"
  type = "gcp_cloud_storage"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The GCS bucket name.
  #
  # * required
  # * type: string
  bucket = "my-bucket"

  # The compression mechanism to use.
  #
  # * required
  # * type: string
  # * enum: "gzip" or "none"
  compression = "gzip"
  compression = "none"

  # The filename for a Google Cloud service account credentials JSON file used to
  # authenticate access to the Cloud Storage API. If this is unset, Vector checks
  # the `$GOOGLE_APPLICATION_CREDENTIALS` environment variable for a filename.
  #
  # * required
  # * type: string
  credentials_path = "/path/to/credentials.json"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  #
  # Object Names
  #

  # Whether or not to append a UUID v4 token to the end of the file. This ensures
  # there are no name collisions high volume use cases.
  #
  # * required
  # * default: true
  # * type: bool
  filename_append_uuid = true
  filename_append_uuid = false

  # The filename extension to use in the object name.
  #
  # * required
  # * default: "log"
  # * type: string
  filename_extension = "log"

  # The format of the resulting object file name. `strftime` specifiers are
  # supported.
  #
  # * required
  # * default: "%s"
  # * type: string
  filename_time_format = "%s"

  # A prefix to apply to all object key names. This should be used to partition
  # your objects, and it's important to end this value with a `/` if you want
  # this to be the root GCS "folder".
  #
  # * optional
  # * default: "date=%F/"
  # * type: string
  key_prefix = "date=%F/"
  key_prefix = "date=%F/hour=%H/"
  key_prefix = "year=%Y/month=%m/day=%d/"
  key_prefix = "application_id={{ application_id }}/date=%F/"

  #
  # requests
  #

  # The encoding format used to serialize the events before outputting.
  #
  # * required
  # * type: string
  # * enum: "ndjson" or "text"
  encoding = "ndjson"
  encoding = "text"

  #
  # Object Attributes
  #

  # Predefined ACL to apply to the created objects. For more information, see
  # Predefined ACLs.
  #
  # * optional
  # * no default
  # * type: string
  # * enum: "authenticatedRead", "bucketOwnerFullControl", "bucketOwnerRead", "private", "projectPrivate", and "publicRead"
  acl = "authenticatedRead"
  acl = "bucketOwnerFullControl"
  acl = "bucketOwnerRead"
  acl = "private"
  acl = "projectPrivate"
  acl = "publicRead"

  # The set of metadata `key:value` pairs for the created objects. See the GCS
  # custom metadata documentation for more details.
  #
  # * optional
  # * no default
  # * type: string

  # The storage class for the created objects. See the GCP storage classes for
  # more details.
  #
  # * optional
  # * no default
  # * type: string
  # * enum: "STANDARD", "NEARLINE", "COLDLINE", and "ARCHIVE"
  storage_class = "STANDARD"
  storage_class = "NEARLINE"
  storage_class = "COLDLINE"
  storage_class = "ARCHIVE"

  #
  # Batch
  #

  [sinks.gcp_cloud_storage.batch]
    # The maximum size of a batch, in bytes, before it is flushed.
    #
    # * required
    # * default: 10485760
    # * type: int
    # * unit: bytes
    max_size = 10485760

    # The maximum age of a batch before it is flushed.
    #
    # * required
    # * default: 300
    # * type: int
    # * unit: seconds
    timeout_secs = 300

  #
  # Buffer
  #

  [sinks.gcp_cloud_storage.buffer]
    # The buffer's type and storage mechanism.
    #
    # * required
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * required
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Request
  #

  [sinks.gcp_cloud_storage.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: int
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 1000
    # * type: int
    rate_limit_num = 1000

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: -1
    # * type: int
    retry_attempts = -1

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: int
    # * unit: seconds
    timeout_secs = 60

  #
  # Tls
  #

  [sinks.gcp_cloud_storage.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509).
    #
    # * optional
    # * no default
    # * type: string
    ca_path = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12. If this is set and is not a PKCS#12
    # archive, `key_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_path = "/path/to/host_certificate.crt"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_path` is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

    # Absolute path to a certificate key file used to identify this connection, in
    # DER or PEM format (PKCS#8). If this is set, `crt_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_path = "/path/to/host_certificate.key"

    # If `true` (the default), Vector will validate the TLS certificate of the
    # remote host. Do NOT set this to `false` unless you understand the risks of
    # not verifying the remote certificate.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_certificate = true
    verify_certificate = false

    # If `true` (the default), Vector will validate the configured remote host name
    # against the remote host's TLS certificate. Do NOT set this to `false` unless
    # you understand the risks of not verifying the remote hostname.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_hostname = true
    verify_hostname = false

# Batches `log` events to Google Cloud Platform's Pubsub service via the REST Interface.
[sinks.gcp_pubsub]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "gcp_pubsub"
  type = "gcp_pubsub"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The project name to which to publish logs.
  #
  # * required
  # * type: string
  project = "vector-123456"

  # The topic within the project to which to publish logs.
  #
  # * required
  # * type: string
  topic = "this-is-a-topic"

  # A Google Cloud API key used to authenticate access the pubsub project and
  # topic. Either this or `credentials_path` must be set.
  #
  # * optional
  # * no default
  # * type: string
  api_key = "${GCP_API_KEY_ENV_VAR}"
  api_key = "ef8d5de700e7989468166c40fc8a0ccd"

  # The filename for a Google Cloud service account credentials JSON file used to
  # authenticate access to the pubsub project and topic. If this is unset, Vector
  # checks the `$GOOGLE_APPLICATION_CREDENTIALS` environment variable for a
  # filename.
  #
  # * optional
  # * no default
  # * type: string
  credentials_path = "/path/to/credentials.json"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  #
  # Batch
  #

  [sinks.gcp_pubsub.batch]
    # The maximum size of a batch, in bytes, before it is flushed.
    #
    # * required
    # * default: 10485760
    # * type: int
    # * unit: bytes
    max_size = 10485760

    # The maximum age of a batch before it is flushed.
    #
    # * required
    # * default: 1
    # * type: int
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.gcp_pubsub.buffer]
    # The buffer's type and storage mechanism.
    #
    # * required
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * required
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Request
  #

  [sinks.gcp_pubsub.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: int
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 100
    # * type: int
    rate_limit_num = 100

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: -1
    # * type: int
    retry_attempts = -1

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: int
    # * unit: seconds
    timeout_secs = 60

  #
  # Tls
  #

  [sinks.gcp_pubsub.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509).
    #
    # * optional
    # * no default
    # * type: string
    ca_path = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12. If this is set and is not a PKCS#12
    # archive, `key_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_path = "/path/to/host_certificate.crt"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_path` is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

    # Absolute path to a certificate key file used to identify this connection, in
    # DER or PEM format (PKCS#8). If this is set, `crt_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_path = "/path/to/host_certificate.key"

    # If `true` (the default), Vector will validate the TLS certificate of the
    # remote host. Do NOT set this to `false` unless you understand the risks of
    # not verifying the remote certificate.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_certificate = true
    verify_certificate = false

    # If `true` (the default), Vector will validate the configured remote host name
    # against the remote host's TLS certificate. Do NOT set this to `false` unless
    # you understand the risks of not verifying the remote hostname.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_hostname = true
    verify_hostname = false

# Batches `log` events to Google Cloud Platform's Stackdriver Logging service via the REST Interface.
[sinks.gcp_stackdriver_logging]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "gcp_stackdriver_logging"
  type = "gcp_stackdriver_logging"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The filename for a Google Cloud service account credentials JSON file used to
  # authenticate access to the Stackdriver Logging API. If this is unset, Vector
  # checks the `$GOOGLE_APPLICATION_CREDENTIALS` environment variable for a
  # filename.
  #
  # * required
  # * type: string
  credentials_path = "/path/to/credentials.json"

  # The log ID to which to publish logs. This is a name you create to identify
  # this log stream.
  #
  # * required
  # * type: string
  log_id = "vector-logs"

  # The project ID to which to publish logs. See the Google Cloud Platform
  # project management documentation for more details.
  #
  # Exactly one of `billing_account_id`, `folder_id`, `organization_id`, or
  # `project_id` must be set.
  #
  # * required
  # * type: string
  project_id = "vector-123456"

  # The billing account ID to which to publish logs.
  #
  # Exactly one of `billing_account_id`, `folder_id`, `organization_id`, or
  # `project_id` must be set.
  #
  # * optional
  # * no default
  # * type: string
  billing_account_id = "012345-6789AB-CDEF01"

  # The folder ID to which to publish logs.
  # See the Google Cloud Platform folder documentation for more details.
  #
  # Exactly one of `billing_account_id`, `folder_id`, `organization_id`, or
  # `project_id` must be set.
  #
  # * optional
  # * no default
  # * type: string
  folder_id = "My Folder"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # The organization ID to which to publish logs. This would be the identifier
  # assigned to your organization on Google Cloud Platform.
  #
  # Exactly one of `billing_account_id`, `folder_id`, `organization_id`, or
  # `project_id` must be set.
  #
  # * optional
  # * no default
  # * type: string
  organization_id = "622418129737"

  #
  # Batch
  #

  [sinks.gcp_stackdriver_logging.batch]
    # The maximum size of a batch, in bytes, before it is flushed.
    #
    # * required
    # * default: 5242880
    # * type: int
    # * unit: bytes
    max_size = 5242880

    # The maximum age of a batch before it is flushed.
    #
    # * required
    # * default: 1
    # * type: int
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.gcp_stackdriver_logging.buffer]
    # The buffer's type and storage mechanism.
    #
    # * required
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * required
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Request
  #

  [sinks.gcp_stackdriver_logging.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: int
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 1000
    # * type: int
    rate_limit_num = 1000

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: -1
    # * type: int
    retry_attempts = -1

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: int
    # * unit: seconds
    timeout_secs = 60

  #
  # Resource
  #

  [sinks.gcp_stackdriver_logging.resource]
    # The monitored resource type. For example, the type of a Compute Engine VM
    # instance is gce_instance.
    #
    # See the Google Cloud Platform monitored resource documentation for more
    # details.
    #
    # * required
    # * type: string
    type = "global"
    type = "gce_instance"

    # Values for all of the labels listed in the associated monitored resource
    # descriptor.
    #
    # For example, Compute Engine VM instances use the labels `projectId`,
    # `instanceId`, and `zone`.
    #
    # * optional
    # * no default
    # * type: string
    projectId = "vector-123456"
    zone = "Twilight"

  #
  # Tls
  #

  [sinks.gcp_stackdriver_logging.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509).
    #
    # * optional
    # * no default
    # * type: string
    ca_path = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12. If this is set and is not a PKCS#12
    # archive, `key_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_path = "/path/to/host_certificate.crt"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_path` is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

    # Absolute path to a certificate key file used to identify this connection, in
    # DER or PEM format (PKCS#8). If this is set, `crt_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_path = "/path/to/host_certificate.key"

    # If `true` (the default), Vector will validate the TLS certificate of the
    # remote host. Do NOT set this to `false` unless you understand the risks of
    # not verifying the remote certificate.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_certificate = true
    verify_certificate = false

    # If `true` (the default), Vector will validate the configured remote host name
    # against the remote host's TLS certificate. Do NOT set this to `false` unless
    # you understand the risks of not verifying the remote hostname.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_hostname = true
    verify_hostname = false

# Batches `log` events to a generic HTTP endpoint.
[sinks.http]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "http"
  type = "http"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The full URI to make HTTP requests to. This should include the protocol and
  # host, but can also include the port, path, and any other valid part of a URI.
  #
  # * required
  # * type: string
  uri = "https://10.22.212.22:9000/endpoint"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # A URI that Vector can request in order to determine the service health.
  #
  # * optional
  # * no default
  # * type: string
  healthcheck_uri = "https://10.22.212.22:9000/_health"

  #
  # requests
  #

  # The encoding format used to serialize the events before outputting.
  #
  # * required
  # * type: string
  # * enum: "json", "ndjson", and "text"
  encoding = "json"
  encoding = "ndjson"
  encoding = "text"

  # The compression strategy used to compress the encoded event data before
  # outputting.
  #
  # * optional
  # * default: "none"
  # * type: string
  # * enum: "none" or "gzip"
  compression = "none"
  compression = "gzip"

  #
  # Auth
  #

  [sinks.http.auth]
    # The authentication strategy to use.
    #
    # * required
    # * type: string
    # * must be: "basic"
    strategy = "basic"

    # The basic authentication password.
    #
    # * required
    # * type: string
    # * relevant when strategy = "basic"
    password = "${PASSWORD_ENV_VAR}"
    password = "password"

    # The basic authentication user name.
    #
    # * required
    # * type: string
    # * relevant when strategy = "basic"
    user = "${USERNAME_ENV_VAR}"
    user = "username"

  #
  # Batch
  #

  [sinks.http.batch]
    # The maximum size of a batch, in bytes, before it is flushed.
    #
    # * required
    # * default: 1049000
    # * type: int
    # * unit: bytes
    max_size = 1049000

    # The maximum age of a batch before it is flushed.
    #
    # * required
    # * default: 1
    # * type: int
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.http.buffer]
    # The buffer's type and storage mechanism.
    #
    # * required
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * required
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Headers
  #

  [sinks.http.headers]
    # A custom header to be added to each outgoing HTTP request.
    #
    # * required
    # * type: string
    Authorization = "${TOKEN_ENV_VAR}"
    X-Powered-By = "Vector"

  #
  # Request
  #

  [sinks.http.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: requests
    in_flight_limit = 10

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 1000
    # * type: int
    rate_limit_num = 1000

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: -1
    # * type: int
    retry_attempts = -1

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 30
    # * type: int
    # * unit: seconds
    timeout_secs = 30

  #
  # Tls
  #

  [sinks.http.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509).
    #
    # * optional
    # * no default
    # * type: string
    ca_path = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12. If this is set and is not a PKCS#12
    # archive, `key_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_path = "/path/to/host_certificate.crt"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_path` is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

    # Absolute path to a certificate key file used to identify this connection, in
    # DER or PEM format (PKCS#8). If this is set, `crt_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_path = "/path/to/host_certificate.key"

    # If `true` (the default), Vector will validate the TLS certificate of the
    # remote host. Do NOT set this to `false` unless you understand the risks of
    # not verifying the remote certificate.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_certificate = true
    verify_certificate = false

    # If `true` (the default), Vector will validate the configured remote host name
    # against the remote host's TLS certificate. Do NOT set this to `false` unless
    # you understand the risks of not verifying the remote hostname.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_hostname = true
    verify_hostname = false

# Batches `log` events to Humio via the HEC API.
[sinks.humio_logs]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "humio_logs"
  type = "humio_logs"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # Your Humio ingestion token.
  #
  # * required
  # * type: string
  token = "${TOKEN_ENV_VAR}"
  token = "A94A8FE5CCB19BA61C4C08"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # The optional host to send Humio logs to.
  #
  # * optional
  # * no default
  # * type: string
  host = "http://myhumiohost.com"

  #
  # Batch
  #

  [sinks.humio_logs.batch]
    # The maximum size of a batch, in bytes, before it is flushed.
    #
    # * required
    # * default: 1049000
    # * type: int
    # * unit: bytes
    max_size = 1049000

    # The maximum age of a batch before it is flushed.
    #
    # * required
    # * default: 1
    # * type: int
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.humio_logs.buffer]
    # The buffer's type and storage mechanism.
    #
    # * required
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * required
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Request
  #

  [sinks.humio_logs.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: requests
    in_flight_limit = 10

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 10
    # * type: int
    rate_limit_num = 10

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: -1
    # * type: int
    retry_attempts = -1

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: int
    # * unit: seconds
    timeout_secs = 60

# Batches `metric` events to InfluxDB using v1 or v2 HTTP API.
[sinks.influxdb_metrics]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "influxdb_metrics"
  type = "influxdb_metrics"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The destination bucket for writes into InfluxDB 2.
  #
  # * required
  # * type: string
  bucket = "vector-bucket"
  bucket = "4d2225e4d3d49f75"

  # Sets the target database for the write into InfluxDB 1.
  #
  # * required
  # * type: string
  database = "vector-database"
  database = "iot-store"

  # InfluxDB endpoint to send metrics to.
  #
  # * required
  # * type: string
  endpoint = "https://us-west-2-1.aws.cloud2.influxdata.com"
  endpoint = "http://localhost:8086/"

  # A prefix that will be added to all metric names.
  #
  # * required
  # * type: string
  namespace = "service"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  #
  # auth
  #

  # Specifies the destination organization for writes into InfluxDB 2.
  #
  # * required
  # * type: string
  org = "Organization"
  org = "33f2cff0a28e5b63"

  # Authentication token for InfluxDB 2.
  #
  # * required
  # * type: string
  token = "${INFLUXDB_TOKEN_ENV_VAR}"
  token = "ef8d5de700e7989468166c40fc8a0ccd"

  # Sets the password for authentication if you’ve enabled authentication for the
  # write into InfluxDB 1.
  #
  # * optional
  # * no default
  # * type: string
  password = "${INFLUXDB_PASSWORD_ENV_VAR}"
  password = "influxdb4ever"

  # Sets the username for authentication if you’ve enabled authentication for the
  # write into InfluxDB 1.
  #
  # * optional
  # * no default
  # * type: string
  username = "todd"
  username = "vector-source"

  #
  # persistence
  #

  # Sets the write consistency for the point for InfluxDB 1.
  #
  # * optional
  # * no default
  # * type: string
  consistency = "any"
  consistency = "one"
  consistency = "quorum"
  consistency = "all"

  # Sets the target retention policy for the write into InfluxDB 1.
  #
  # * optional
  # * no default
  # * type: string
  retention_policy_name = "autogen"
  retention_policy_name = "one_day_only"

  #
  # Batch
  #

  [sinks.influxdb_metrics.batch]
    # The maximum size of a batch, in events, before it is flushed.
    #
    # * required
    # * default: 20
    # * type: int
    # * unit: events
    max_events = 20

    # The maximum age of a batch before it is flushed.
    #
    # * required
    # * default: 1
    # * type: int
    # * unit: seconds
    timeout_secs = 1

  #
  # Request
  #

  [sinks.influxdb_metrics.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: int
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 5
    # * type: int
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: -1
    # * type: int
    retry_attempts = -1

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: int
    # * unit: seconds
    timeout_secs = 60

# Streams `log` events to Apache Kafka via the Kafka protocol.
[sinks.kafka]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "kafka"
  type = "kafka"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # A comma delimited list of host and port pairs that the Kafka client should
  # contact to bootstrap its cluster metadata.
  #
  # * required
  # * type: string
  bootstrap_servers = "10.14.22.123:9092,10.14.23.332:9092"

  # The log field name to use for the topic key. If unspecified, the key will be
  # randomly generated. If the field does not exist on the log, a blank value
  # will be used.
  #
  # * required
  # * type: string
  key_field = "user_id"

  # The Kafka topic name to write events to.
  #
  # * required
  # * type: string
  topic = "topic-1234"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # Local message timeout.
  #
  # * optional
  # * default: 300000
  # * type: int
  message_timeout_ms = 150000
  message_timeout_ms = 450000

  # Default timeout for network requests.
  #
  # * optional
  # * default: 60000
  # * type: int
  socket_timeout_ms = 30000
  socket_timeout_ms = 90000

  #
  # requests
  #

  # The encoding format used to serialize the events before outputting.
  #
  # * required
  # * type: string
  # * enum: "json" or "text"
  encoding = "json"
  encoding = "text"

  #
  # Advanced
  #

  [sinks.kafka.librdkafka_options]
    # The options and their values. Accepts `string` values.
    #
    # * optional
    # * no default
    # * type: string
    "client.id" = "${ENV_VAR}"
    "socket.send.buffer.bytes" = "100"

  #
  # Buffer
  #

  [sinks.kafka.buffer]
    # The buffer's type and storage mechanism.
    #
    # * required
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * required
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Tls
  #

  [sinks.kafka.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509).
    #
    # * optional
    # * no default
    # * type: string
    ca_path = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12. If this is set and is not a PKCS#12
    # archive, `key_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_path = "/path/to/host_certificate.crt"

    # Enable TLS during connections to the remote.
    #
    # * optional
    # * default: false
    # * type: bool
    enabled = false
    enabled = true

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_path` is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

    # Absolute path to a certificate key file used to identify this connection, in
    # DER or PEM format (PKCS#8). If this is set, `crt_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_path = "/path/to/host_certificate.key"

# Batches `log` events to LogDna's HTTP Ingestion API.
[sinks.logdna]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "logdna"
  type = "logdna"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The Ingestion API key.
  #
  # * required
  # * type: string
  api_key = "${LOGDNA_API_KEY_ENV_VAR}"
  api_key = "ef8d5de700e7989468166c40fc8a0ccd"

  # The hostname that will be attached to each batch of events.
  #
  # * required
  # * type: string
  hostname = "my-local-machine"

  # The default app that will be set for events that do not contain a `file` or
  # `app` field.
  #
  # * optional
  # * default: "vector"
  # * type: string
  default_app = "vector"
  default_app = "myapp"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # An optional host that will override the default one.
  #
  # * optional
  # * no default
  # * type: string
  host = "http://127.0.0.1"
  host = "http://example.com"

  # The IP address that will be attached to each batch of events.
  #
  # * optional
  # * no default
  # * type: string
  ip = "0.0.0.0"

  # The mac address that will be attached to each batch of events.
  #
  # * optional
  # * no default
  # * type: string
  mac = "my-mac-address"

  # The tags that will be attached to each batch of events.
  #
  # * optional
  # * no default
  # * type: [string]
  tags = ["tag1", "tag2"]

  #
  # Batch
  #

  [sinks.logdna.batch]
    # The maximum size of a batch, in bytes, before it is flushed.
    #
    # * required
    # * default: 10490000
    # * type: int
    # * unit: bytes
    max_size = 10490000

    # The maximum age of a batch before it is flushed.
    #
    # * required
    # * default: 1
    # * type: int
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.logdna.buffer]
    # The buffer's type and storage mechanism.
    #
    # * required
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * required
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Request
  #

  [sinks.logdna.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: int
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 5
    # * type: int
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: -1
    # * type: int
    retry_attempts = -1

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: int
    # * unit: seconds
    timeout_secs = 60

# Batches `log` events to Loki.
[sinks.loki]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "loki"
  type = "loki"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The encoding format used to serialize the events before outputting.
  #
  # * required
  # * type: string
  # * enum: "json" or "text"
  encoding = "json"
  encoding = "text"

  # The endpoint used to ship logs to.
  #
  # * required
  # * type: string
  endpoint = "http://localhost:3100"
  endpoint = "http://127.0.0.1:8080"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # If this is set to `true` then when labels are collected from events those
  # fields will also get removed from the event.
  #
  # * optional
  # * default: false
  # * type: bool
  remove_label_fields = false
  remove_label_fields = true

  # If this is set to `true` then the timestamp will be removed from the event.
  # This is useful because loki uses the timestamp to index the event.
  #
  # * optional
  # * default: true
  # * type: bool
  remove_timestamp = true
  remove_timestamp = false

  # The tenant id that will be sent with every request, by default this is not
  # required since a proxy should set this header. When running loki locally a
  # tenant id is not required either.
  #
  # You can read more about tenant id's here
  #
  # * optional
  # * no default
  # * type: string
  tenant_id = "some_tenant_id"

  #
  # Auth
  #

  [sinks.loki.auth]
    # The authentication strategy to use.
    #
    # * required
    # * type: string
    # * must be: "basic"
    strategy = "basic"

    # The basic authentication password.If using GrafanaLab's hosted Loki then this
    # must be setto your `instanceId`.
    #
    # * required
    # * type: string
    # * relevant when strategy = "basic"
    password = "${PASSWORD_ENV_VAR}"
    password = "password"

    # The basic authentication user name.If using GrafanaLab's hosted Loki then
    # this must be setto your Grafana.com api key.
    #
    # * required
    # * type: string
    # * relevant when strategy = "basic"
    user = "${USERNAME_ENV_VAR}"
    user = "username"

  #
  # Batch
  #

  [sinks.loki.batch]
    # The maximum size of a batch, in bytes, before it is flushed.
    #
    # * required
    # * default: 10490000
    # * type: int
    # * unit: bytes
    max_size = 10490000

    # The maximum age of a batch before it is flushed.
    #
    # * required
    # * default: 1
    # * type: int
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.loki.buffer]
    # The buffer's type and storage mechanism.
    #
    # * required
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * required
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Labels
  #

  [sinks.loki.labels]
    # A key-value pair for labels.
    #
    # * required
    # * type: string
    key = "value"
    key = "{{ event_field }}"

  #
  # Request
  #

  [sinks.loki.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: int
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 5
    # * type: int
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: -1
    # * type: int
    retry_attempts = -1

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: int
    # * unit: seconds
    timeout_secs = 60

  #
  # Tls
  #

  [sinks.loki.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509).
    #
    # * optional
    # * no default
    # * type: string
    ca_path = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12. If this is set and is not a PKCS#12
    # archive, `key_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_path = "/path/to/host_certificate.crt"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_path` is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

    # Absolute path to a certificate key file used to identify this connection, in
    # DER or PEM format (PKCS#8). If this is set, `crt_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_path = "/path/to/host_certificate.key"

    # If `true` (the default), Vector will validate the TLS certificate of the
    # remote host. Do NOT set this to `false` unless you understand the risks of
    # not verifying the remote certificate.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_certificate = true
    verify_certificate = false

    # If `true` (the default), Vector will validate the configured remote host name
    # against the remote host's TLS certificate. Do NOT set this to `false` unless
    # you understand the risks of not verifying the remote hostname.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_hostname = true
    verify_hostname = false

# Batches `log` events to New Relic's log service via their log API.
[sinks.new_relic_logs]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "new_relic_logs"
  type = "new_relic_logs"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # Your New Relic insert key (if applicable).
  #
  # * optional
  # * no default
  # * type: string
  insert_key = "xxxx"
  insert_key = "${INSERT_KEY_ENV_VAR}"

  # Your New Relic license key (if applicable).
  #
  # * optional
  # * no default
  # * type: string
  license_key = "xxxx"
  license_key = "${LICENSE_KEY_ENV_VAR}"

  # The API region to send logs to.
  #
  # * optional
  # * default: "us"
  # * type: string
  # * enum: "us" or "eu"
  region = "us"
  region = "eu"

  #
  # Batch
  #

  [sinks.new_relic_logs.batch]
    # The maximum size of a batch, in bytes, before it is flushed.
    #
    # * required
    # * default: 524000
    # * type: int
    # * unit: bytes
    max_size = 524000

    # The maximum age of a batch before it is flushed.
    #
    # * required
    # * default: 1
    # * type: int
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.new_relic_logs.buffer]
    # The buffer's type and storage mechanism.
    #
    # * required
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * required
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Request
  #

  [sinks.new_relic_logs.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: int
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 100
    # * type: int
    rate_limit_num = 100

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: -1
    # * type: int
    retry_attempts = -1

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 30
    # * type: int
    # * unit: seconds
    timeout_secs = 30

# Exposes `metric` events to Prometheus metrics service.
[sinks.prometheus]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "prometheus"
  type = "prometheus"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The address to expose for scraping.
  #
  # * required
  # * type: string
  address = "0.0.0.0:9598"

  # Default buckets to use for aggregating distribution metrics into histograms.
  #
  # * required
  # * default: [0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0]
  # * type: [float]
  # * unit: seconds
  buckets = [0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0]

  # Time interval between set values are reset.
  #
  # * required
  # * default: 60
  # * type: int
  # * unit: seconds
  flush_period_secs = 60

  # A prefix that will be added to all metric names.
  # It should follow Prometheus naming conventions.
  #
  # * required
  # * type: string
  namespace = "service"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

# Batches `log` events to Sematext via the Elasticsearch API.
[sinks.sematext_logs]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "sematext_logs"
  type = "sematext_logs"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The token that will be used to write to Sematext.
  #
  # * required
  # * type: string
  token = "${SEMATEXT_TOKEN_ENV_VAR}"
  token = "some-sematext-token"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # The host that will be used to send logs to. This option is required if
  # `region` is not set.
  #
  # * optional
  # * no default
  # * type: string
  host = "http://127.0.0.1"
  host = "http://example.com"

  # The region destination to send logs to. This option is required if `host` is
  # not set.
  #
  # * optional
  # * no default
  # * type: string
  region = "na"
  region = "eu"

  #
  # Batch
  #

  [sinks.sematext_logs.batch]
    # The maximum size of a batch, in bytes, before it is flushed.
    #
    # * required
    # * default: 10490000
    # * type: int
    # * unit: bytes
    max_size = 10490000

    # The maximum age of a batch before it is flushed.
    #
    # * required
    # * default: 1
    # * type: int
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.sematext_logs.buffer]
    # The buffer's type and storage mechanism.
    #
    # * required
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * required
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Request
  #

  [sinks.sematext_logs.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: int
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 5
    # * type: int
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: -1
    # * type: int
    retry_attempts = -1

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: int
    # * unit: seconds
    timeout_secs = 60

# Streams `log` events to a socket, such as a TCP or Unix domain socket.
[sinks.socket]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "socket"
  type = "socket"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The address to connect to. The address _must_ include a port.
  #
  # * required
  # * type: string
  # * relevant when mode = "tcp"
  address = "92.12.333.224:5000"

  # The type of socket to use.
  #
  # * required
  # * type: string
  # * enum: "tcp" or "unix"
  mode = "tcp"
  mode = "unix"

  # The unix socket path. This should be the absolute path.
  #
  # * required
  # * type: string
  # * relevant when mode = "unix"
  path = "/path/to/socket"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  #
  # requests
  #

  # The encoding format used to serialize the events before outputting.
  #
  # * required
  # * type: string
  # * enum: "json" or "text"
  encoding = "json"
  encoding = "text"

  #
  # Buffer
  #

  [sinks.socket.buffer]
    # The buffer's type and storage mechanism.
    #
    # * required
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * required
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Tls
  #

  [sinks.socket.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509).
    #
    # * optional
    # * no default
    # * type: string
    ca_path = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12. If this is set and is not a PKCS#12
    # archive, `key_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_path = "/path/to/host_certificate.crt"

    # Enable TLS during connections to the remote.
    #
    # * optional
    # * default: false
    # * type: bool
    enabled = false
    enabled = true

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_path` is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

    # Absolute path to a certificate key file used to identify this connection, in
    # DER or PEM format (PKCS#8). If this is set, `crt_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_path = "/path/to/host_certificate.key"

    # If `true` (the default), Vector will validate the TLS certificate of the
    # remote host. Do NOT set this to `false` unless you understand the risks of
    # not verifying the remote certificate.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_certificate = true
    verify_certificate = false

    # If `true` (the default), Vector will validate the configured remote host name
    # against the remote host's TLS certificate. Do NOT set this to `false` unless
    # you understand the risks of not verifying the remote hostname.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_hostname = true
    verify_hostname = false

# Batches `log` events to a Splunk's HTTP Event Collector.
[sinks.splunk_hec]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "splunk_hec"
  type = "splunk_hec"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # Your Splunk HEC host.
  #
  # * required
  # * type: string
  host = "http://my-splunk-host.com"

  # Your Splunk HEC token.
  #
  # * required
  # * type: string
  token = "${TOKEN_ENV_VAR}"
  token = "A94A8FE5CCB19BA61C4C08"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # Fields to be added to Splunk index.
  #
  # * optional
  # * no default
  # * type: [string]
  # * relevant when encoding = "json"
  indexed_fields = ["field1", "field2"]

  #
  # requests
  #

  # The encoding format used to serialize the events before outputting.
  #
  # * required
  # * type: string
  # * enum: "json" or "text"
  encoding = "json"
  encoding = "text"

  #
  # Batch
  #

  [sinks.splunk_hec.batch]
    # The maximum size of a batch, in bytes, before it is flushed.
    #
    # * required
    # * default: 1049000
    # * type: int
    # * unit: bytes
    max_size = 1049000

    # The maximum age of a batch before it is flushed.
    #
    # * required
    # * default: 1
    # * type: int
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.splunk_hec.buffer]
    # The buffer's type and storage mechanism.
    #
    # * required
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * required
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Request
  #

  [sinks.splunk_hec.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: requests
    in_flight_limit = 10

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 10
    # * type: int
    rate_limit_num = 10

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: -1
    # * type: int
    retry_attempts = -1

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: int
    # * unit: seconds
    timeout_secs = 60

  #
  # Tls
  #

  [sinks.splunk_hec.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509).
    #
    # * optional
    # * no default
    # * type: string
    ca_path = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12. If this is set and is not a PKCS#12
    # archive, `key_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_path = "/path/to/host_certificate.crt"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_path` is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

    # Absolute path to a certificate key file used to identify this connection, in
    # DER or PEM format (PKCS#8). If this is set, `crt_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_path = "/path/to/host_certificate.key"

    # If `true` (the default), Vector will validate the TLS certificate of the
    # remote host. Do NOT set this to `false` unless you understand the risks of
    # not verifying the remote certificate.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_certificate = true
    verify_certificate = false

    # If `true` (the default), Vector will validate the configured remote host name
    # against the remote host's TLS certificate. Do NOT set this to `false` unless
    # you understand the risks of not verifying the remote hostname.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_hostname = true
    verify_hostname = false

# Streams `metric` events to StatsD metrics service.
[sinks.statsd]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "statsd"
  type = "statsd"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # A prefix that will be added to all metric names.
  #
  # * required
  # * type: string
  namespace = "service"

  # The UDP socket address to send stats to.
  #
  # * optional
  # * default: "127.0.0.1:8125"
  # * type: string
  address = "127.0.0.1:8125"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

# Streams `log` events to another downstream `vector` source.
[sinks.vector]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "vector"
  type = "vector"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The downstream Vector address to connect to. The address _must_ include a
  # port.
  #
  # * required
  # * type: string
  address = "92.12.333.224:5000"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  #
  # Buffer
  #

  [sinks.vector.buffer]
    # The buffer's type and storage mechanism.
    #
    # * required
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * required
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"
